{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import transforms, models\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from deformable_conv import DeformableConv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Makeup_Cosmetic - Makeup_Co_5\n",
    "Makeup_Impersonation - Makeup_Im_1\n",
    "Makeup_Obfuscation - Makeup_Ob_1\n",
    "Mannequin - Mask_Mann_1\n",
    "Mask_HalfMask - Mask_Half_1\n",
    "Mask_PaperMask - Mask_Paper_1\n",
    "Mask_TransparentMask - Mask_Trans_51\n",
    "Paper - Paper_1\n",
    "Partial_Eye - Partial_Eye_3\n",
    "Partial_FunnyeyeGlasses - Partial_Funnyeye_1\n",
    "Partial_Mouth - Partial_Mouth_1\n",
    "Partial_PaperGlasses - Partial_Paperglass_1\n",
    "Replay - Replay_2\n",
    "Silicone - Mask_Silicone_4\n",
    "'''\n",
    "\n",
    "attack_to_cls = {\n",
    "    'Makeup_Co': 1,\n",
    "    'Makeup_Im': 2,\n",
    "    'Makeup_Ob': 3,\n",
    "    'Mask_Mann': 4,\n",
    "    'Mask_Half': 5,\n",
    "    'Mask_Paper': 6,\n",
    "    'Mask_Trans': 7,\n",
    "    'Paper': 8,\n",
    "    'Partial_Eye': 9,\n",
    "    'Partial_Funnyeye': 10,\n",
    "    'Partial_Mouth': 11,\n",
    "    'Partial_Paperglass': 12,\n",
    "    'Replay': 13,\n",
    "    'Mask_Silicone': 14\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiWMv2Dataset(Dataset):\n",
    "    def __init__(self, live_path, spoof_path, live_ref, spoof_ref):\n",
    "        self.transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(),transforms.Normalize(mean=[0.5], std=[0.5])])\n",
    "        self.live_path = live_path\n",
    "        self.spoof_path = spoof_path\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.sub_levels = []\n",
    "        self.real = 0\n",
    "        self.attack = 1\n",
    "        \n",
    "        with open(live_ref, 'r') as f:\n",
    "            content = f.read()\n",
    "        live_dirs = content.split('\\n')\n",
    "        \n",
    "        with open(spoof_ref, 'r') as f:\n",
    "            content = f.read()\n",
    "        spoof_dirs = content.split('\\n')\n",
    "        \n",
    "        for ldir in live_dirs:\n",
    "            if ldir != '' and ldir != ' ':\n",
    "                ldir_path = os.path.join(self.live_path, ldir)\n",
    "                if os.path.exists(ldir_path):\n",
    "                    lcontent = os.listdir(ldir_path)\n",
    "                    lcontent = [os.path.join(ldir_path, f) for f in lcontent if f.endswith('png')]\n",
    "                    self.images.extend(lcontent)\n",
    "                    self.labels.extend([self.real] * len(lcontent))\n",
    "                    self.sub_levels.extend([self.real] * len(lcontent))\n",
    "                else:\n",
    "                    print(ldir_path)\n",
    "        \n",
    "        for sdir in spoof_dirs:\n",
    "            if sdir != '' and sdir != ' ':\n",
    "                sdir_path = os.path.join(self.spoof_path, sdir)\n",
    "                scontent = os.listdir(sdir_path)\n",
    "                scontent = [os.path.join(sdir_path, f) for f in scontent if f.endswith('png')]\n",
    "                self.images.extend(scontent)\n",
    "                self.labels.extend([self.attack] * len(scontent))\n",
    "                attacklabel = attack_to_cls['_'.join(os.path.basename(sdir).split('_')[:-1])]\n",
    "                self.sub_levels.extend([attacklabel] * len(scontent))\n",
    "        \n",
    "        self.data_len = len(self.images)\n",
    "        \n",
    "\n",
    "    def __len__(self): # returns the total number of samples in the dataset\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, idx): # loads and returns a sample from the dataset at the given index\n",
    "        imgpath = self.images[idx]\n",
    "        img = Image.open(imgpath).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return img, self.labels[idx], self.sub_levels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/ssd2/shakeel-workspace/DOWNLOAD/SiW-Mv2_preprocessed/Live/Live_893\n",
      "/data/ssd2/shakeel-workspace/DOWNLOAD/SiW-Mv2_preprocessed/Live/Live_896\n",
      "/data/ssd2/shakeel-workspace/DOWNLOAD/SiW-Mv2_preprocessed/Live/Live_899\n",
      "/data/ssd2/shakeel-workspace/DOWNLOAD/SiW-Mv2_preprocessed/Live/Live_900\n",
      "Training set size: 110019\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(0)\n",
    "\n",
    "class_label_real = 0\n",
    "class_label_attack = 1\n",
    "\n",
    "real_dir = r'/data/ssd2/shakeel-workspace/DOWNLOAD/SiW-Mv2_preprocessed/Live/'\n",
    "spoof_dir = r'/data/ssd2/shakeel-workspace/DOWNLOAD/SiW-Mv2_preprocessed/Spoof_root/'\n",
    "\n",
    "# Protocol 1\n",
    "\n",
    "train_spoof_ref = r'/data/ssd2/shakeel-workspace/DOWNLOAD/SiW-Mv2_preprocessed/trainlist_all.txt'\n",
    "train_live_ref = r'/data/ssd2/shakeel-workspace/DOWNLOAD/SiW-Mv2_preprocessed/trainlist_live.txt'\n",
    "test_spoof_ref = r'/data/ssd2/shakeel-workspace/DOWNLOAD/SiW-Mv2_preprocessed/testlist_all.txt'\n",
    "test_live_ref =r'/data/ssd2/shakeel-workspace/DOWNLOAD/SiW-Mv2_preprocessed/testlist_live.txt'\n",
    "\n",
    "# train_spoof_ref = r'protocol_1/train_spoof.txt'\n",
    "# train_live_ref = r'protocol_1/train_live.txt'\n",
    "# val_spoof_ref = r'protocol_1/val_spoof.txt'\n",
    "# val_live_ref = r'protocol_1/val_live.txt'\n",
    "# test_spoof_ref = r'/data/ssd2/shakeel-workspace/DOWNLOAD/SiW-Mv2_preprocessed/testlist_all.txt'\n",
    "# test_live_ref =r'/data/ssd2/shakeel-workspace/DOWNLOAD/SiW-Mv2_preprocessed/testlist_live.txt'\n",
    "\n",
    "# train_dataset = SiWMv2Dataset(real_dir, spoof_dir, train_live_ref, train_spoof_ref)\n",
    "# val_dataset = SiWMv2Dataset(real_dir, spoof_dir, val_live_ref, val_spoof_ref)\n",
    "test_dataset = SiWMv2Dataset(real_dir, spoof_dir, test_live_ref, test_spoof_ref)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size  = 64, shuffle = True, pin_memory = True, num_workers = 8)\n",
    "# val_loader = DataLoader(val_dataset, batch_size  = 64, shuffle = True, pin_memory = True, num_workers = 8)\n",
    "test_loader = DataLoader(test_dataset, batch_size  = 64, shuffle = True, pin_memory = True, num_workers = 8)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Training set size: {len(test_dataset)}\")\n",
    "# print(f\"Training set size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eslab/anaconda3/envs/facerec_new/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/eslab/anaconda3/envs/facerec_new/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Sequential(\n",
      "      (0): DeformableConv2d(\n",
      "        (offset_conv): Conv2d(320, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (modulator_conv): Conv2d(320, 9, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (regular_conv): Conv2d(320, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6()\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet18\n",
    "# model = models.resnet18(pretrained=True)\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# Load pre-trained MobileNetV2\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "# model.features[0] = DeformableConv2d(3, 32, 3, 2, 1)\n",
    "model.features[-1] = nn.Sequential(\n",
    "    DeformableConv2d(320, 1280, 3, 2),\n",
    "    nn.BatchNorm2d(1280),\n",
    "    nn.ReLU6()\n",
    ")\n",
    "model.classifier[1] = nn.Linear(in_features=1280, out_features=2) #default in_features =1280, out_features = 1000\n",
    "\n",
    "# best_model_path = r'checkpoint_protocol_1_wo_val/best_95_0.000376204145941474.pth'\n",
    "# best_model_path = r'checkpoint_protocol_1_wo_val/best_105_0.00012885049953524681.pth'\n",
    "# best_model_path = r'checkpoint_protocol_1_wo_val/best_126_0.00012175165403143548.pth'\n",
    "best_model_path = r'checkpoint_protocol_1_wo_val/best_142_4.0373697962606216e-07.pth'  #3.009\n",
    "# best_model_path = r'checkpoint_protocol_1_wo_val_cont/best_2_0.0005171791127407008.pth'\n",
    "# best_model_path = r'checkpoint_protocol_1_wo_val/best_32_0.0007601213937333313.pth'\n",
    "# best_model_path = r'checkpoint_protocol_1_wo_val/best_135_0.00016639192170754796.pth'\n",
    "# best_model_path = r'checkpoint_protocol_1_wo_val_cont/best_127_2.6473109944895285e-05.pth'\n",
    "# best_model_path = r'checkpoint_protocol_1_wo_val_cont/best_188_5.549576379481903e-05.pth'\n",
    "state_dict = torch.load(best_model_path,  map_location=device)\n",
    "model.load_state_dict(state_dict, strict = True)\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 95.16%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    test_cat_labels = torch.empty(0, dtype=torch.int64, device=device)\n",
    "    test_cat_labels_sub = torch.empty(0, dtype=torch.int64, device = device)\n",
    "    test_predicted_cat_labels = torch.empty(0, dtype=torch.int64, device=device)\n",
    "\n",
    "    for test_images, test_labels, test_labels_sub in test_loader:\n",
    "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "        test_labels_sub = test_labels_sub.to(device)\n",
    "        test_model_op = model(test_images)\n",
    "        _, test_predicted = torch.max(test_model_op, 1)\n",
    "        test_correct += (test_predicted == test_labels).sum().item() \n",
    "        test_total += test_labels.size(0)\n",
    "\n",
    "        test_cat_labels = torch.cat((test_cat_labels, test_labels))\n",
    "        test_cat_labels_sub = torch.cat((test_cat_labels_sub, test_labels_sub))\n",
    "        test_predicted_cat_labels = torch.cat((test_predicted_cat_labels, test_predicted))\n",
    "\n",
    "    test_accuracy = test_correct / test_total * 100  \n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat_labels_cpu = test_cat_labels.cpu()\n",
    "test_cat_labels_sub = test_cat_labels_sub.cpu()\n",
    "test_predicted_cat_labels_cpu = test_predicted_cat_labels.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN: 55137, FP: 575, FN: 4749, TP: 49558\n",
      "Testing Results\n",
      "------------------------------\n",
      "Acc: 0.9516083585562494 \n",
      "Sen: 0.9125527095954481 \n",
      "Spec: 0.9896790637564618 \n",
      "YI: 0.9022317733519098 \n",
      "F1: 0.949023362696285 \n",
      "Prec: 0.9885305088464684 \n",
      "Recall: 0.9125527095954481 \n",
      "HTER: 0.04888411332404505 \n",
      "EER: 0.048391641443750626 \n",
      "BACC: 0.9511158866759549\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_cat_labels_cpu, test_predicted_cat_labels_cpu).ravel()\n",
    "\n",
    "print(f'TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}')\n",
    "\n",
    "acc_score = accuracy_score(test_cat_labels_cpu, test_predicted_cat_labels_cpu)\n",
    "prec_score = precision_score(test_cat_labels_cpu, test_predicted_cat_labels_cpu)\n",
    "recall = recall_score(test_cat_labels_cpu, test_predicted_cat_labels_cpu)\n",
    "\n",
    "Y_I_val =(tp/(tp+fn)) + (tn/(tn+fp)) - 1\n",
    "sensitivity_val = tp / (tp + fn)\n",
    "specificity_val = tn / (tn + fp)\n",
    "f1score_val = 2 * tp / (2 * tp + fp + fn)\n",
    "FAR = fp/(fp + tn)\n",
    "FRR = fn/(fn + tp)\n",
    "HTER_val = (FAR + FRR)/2\n",
    "EER = (fp+fn)/(tn+fp+fn+tp)\n",
    "val_bacc = balanced_accuracy_score(test_cat_labels_cpu, test_predicted_cat_labels_cpu)\n",
    "\n",
    "\n",
    "print('Testing Results')\n",
    "print(30*'-')\n",
    "print('Acc:', acc_score, '\\nSen:', sensitivity_val, '\\nSpec:', specificity_val, '\\nYI:', Y_I_val, '\\nF1:', f1score_val, '\\nPrec:', prec_score, '\\nRecall:', recall, '\\nHTER:', HTER_val, '\\nEER:', EER, '\\nBACC:', val_bacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 1, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predicted_cat_labels_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_real = 0\n",
    "class_label_attack = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ayo = test_cat_labels_sub + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 15,  1,  6,  9, 14,  1,  6,  1,  1,  9,  1, 13, 11,  1,  9,  1, 13,\n",
       "         1, 15,  1,  9, 14,  1, 12,  9,  1,  1,  1, 14,  1, 15, 11,  1, 14,  1,\n",
       "         2,  1,  1, 10,  3,  1,  1,  1,  8, 12,  1,  9,  1,  1,  3, 14,  9, 15,\n",
       "         1, 11,  1,  1, 11,  1, 11,  1,  8,  3,  2, 11,  3, 11, 12,  8,  1,  1,\n",
       "        14,  9,  1,  1,  2,  1, 14,  4, 14,  1,  1,  8,  1, 13,  8,  1,  6,  8,\n",
       "         9, 11,  1,  1,  1,  1,  7,  1,  1,  1,  1, 10, 12,  9,  9,  6, 11,  1,\n",
       "         1, 14,  1,  1, 10,  1,  8,  1,  1,  1,  9,  9,  1,  2,  1,  1,  1,  1,\n",
       "         1,  1,  3,  1, 11,  1,  1,  1,  2, 13,  9,  3,  1,  2,  4,  1, 14,  1,\n",
       "        13,  1,  1,  1,  3,  1,  1,  1,  1,  1,  1,  9, 11,  1,  2,  1,  1,  1,\n",
       "         1, 11,  1,  9,  1,  1, 14, 11,  1,  1,  2,  3, 11,  1,  1, 11,  1,  1,\n",
       "         1, 11,  3, 11, 10,  1,  1,  1, 13, 12,  1,  1,  1, 11,  1,  3,  1,  1,\n",
       "         1, 14,  1,  1,  9, 12,  1,  3,  9,  1, 10,  5,  1, 11,  2,  1, 12,  8,\n",
       "         1,  1,  3, 11,  1,  8,  1, 12,  9, 14,  2,  1, 11, 13,  1,  1,  4, 11,\n",
       "         1, 10,  1,  1, 12,  1,  1,  4, 14,  3,  8, 10, 15,  1,  1,  1,  6,  1,\n",
       "         1, 13,  1,  1,  2,  1,  1,  1,  6, 13,  1,  1,  2,  1,  3,  1, 10,  9,\n",
       "         1,  3,  1,  1,  1,  1,  1,  3,  1, 14,  3,  1,  1,  1,  9, 12,  1,  1,\n",
       "         1, 14, 11,  2, 14,  1,  1,  3,  1, 11,  1, 10,  1,  1,  1,  3,  1,  1,\n",
       "         1,  1,  1, 13,  8,  1,  8,  9,  1,  3,  8,  5,  1,  1,  1,  1,  5, 14,\n",
       "         1,  1, 11, 15, 13,  8, 14, 14,  1,  5,  1,  1, 11, 12,  6,  1, 14, 13,\n",
       "         1,  1, 11, 11,  1,  1,  1,  1,  3, 11,  1,  9, 13, 11,  5,  1,  2,  1,\n",
       "         6,  1,  6, 13,  1,  1,  3,  1,  9,  1,  1,  8, 15,  1,  6,  2, 13, 13,\n",
       "         2,  1,  1,  6,  8,  1,  3,  5,  9,  1,  1,  1,  1,  1,  6,  8,  9,  1,\n",
       "        10,  1,  1,  1,  1,  1,  8,  1, 10,  1, 11, 10,  1,  2,  1,  1,  1,  1,\n",
       "         9,  1,  1,  1,  9, 14,  4,  1,  1, 11,  2, 10,  1,  1,  1, 13,  1,  4,\n",
       "        11,  1, 12, 11, 14,  1,  3,  1,  1,  2,  1, 11, 15,  1, 14,  5,  1, 14,\n",
       "         1, 14, 10,  1,  9,  2,  3,  1,  1,  1, 11,  1,  1, 11,  1,  1,  5,  8,\n",
       "         5,  4,  1,  1,  1, 12,  1,  5,  1, 11,  1,  1,  1, 14,  1, 10, 11,  1,\n",
       "         2, 11,  9,  9,  1, 11, 14,  1,  8, 13,  2,  1,  1,  1,  1, 11,  1,  1,\n",
       "        13, 11, 11, 11,  1,  1, 15,  1,  6,  1,  1, 12,  1, 11,  1,  9,  2,  3,\n",
       "         9,  1,  5,  1, 15,  1,  1, 14,  1, 13,  3,  1,  1, 15, 13,  1,  9,  1,\n",
       "         8,  1, 10,  1,  2, 10, 15,  3,  1,  4,  1, 13, 15, 11,  1, 13,  1, 14,\n",
       "         8,  8, 13, 15, 11,  1,  5, 11,  1,  1,  1, 11,  3,  9,  1, 13, 11, 14,\n",
       "         9,  1,  1,  6,  1,  1, 14, 11, 11, 15,  1,  1,  7, 11,  8,  1,  1,  1,\n",
       "        12,  2,  1,  1,  1,  9,  1,  1,  1, 11,  1,  1,  1,  1,  2,  1,  9,  1,\n",
       "        11,  1, 10,  1,  1,  1,  1,  1,  8,  1,  6,  7,  1,  1,  1, 11,  9,  1,\n",
       "        11,  1,  1,  1,  1,  8,  8,  1,  1,  4,  2,  8,  1,  1,  5,  1,  6,  2,\n",
       "         1, 11,  1,  1, 13, 11, 13,  1,  2,  1,  3, 11,  3,  1, 10,  4,  2,  9,\n",
       "         1, 11,  3,  2,  1, 10,  9,  1,  8,  6,  1,  1,  2,  4, 14,  2,  1,  1,\n",
       "        11,  6, 10,  5,  6,  1,  6,  1,  2,  4, 14,  9,  8, 11, 10, 12, 11,  1,\n",
       "        11,  1,  1,  1,  9,  3,  2,  1,  1,  1,  1,  8,  1, 11,  1,  1,  9,  2,\n",
       "         1,  1,  2,  1,  1,  9,  5,  1,  1,  9,  1,  1,  1, 12,  1,  1,  4,  1,\n",
       "        15,  1,  1,  1,  1, 10, 10,  1,  3,  1,  1,  1,  1,  8,  1, 11,  1,  1,\n",
       "         2,  1,  8,  8,  1, 11,  1, 11, 15, 13, 14, 13, 14,  3,  1,  1,  1,  5,\n",
       "         1,  1,  1,  1,  5,  1, 14, 14,  1, 11,  9, 11,  1, 11,  1,  1,  1,  1,\n",
       "         1,  4, 13, 14,  1,  1,  1,  8,  1,  3,  1, 11, 12, 11,  1,  1, 13,  2,\n",
       "         8,  3,  1,  1,  9,  8,  1, 10,  1, 11,  1,  1,  1,  1, 12,  1,  1,  1,\n",
       "         1,  1,  8, 11, 14,  1,  2,  8,  9, 12, 10, 11,  1,  1, 11, 11,  1,  1,\n",
       "         1,  1,  1,  1,  6, 13, 14,  1,  1,  1,  9,  8,  1, 11, 11,  1,  1, 15,\n",
       "         3,  1,  1,  9,  1, 14,  1,  6, 14, 11, 13,  1,  1,  1,  1,  1, 12,  9,\n",
       "         1,  3,  1,  9,  1, 13,  1, 11,  1,  1, 11, 10,  1,  2, 14,  1,  1,  1,\n",
       "         5, 10,  6,  1, 11,  6,  1,  3,  1,  1, 11,  1, 13,  1,  1,  1,  1,  1,\n",
       "         1,  5,  1,  1,  1,  1,  1, 11,  8,  1,  1,  1, 12, 10,  4, 11, 13,  6,\n",
       "         1,  1,  1,  2,  1,  3,  9, 10,  1, 11,  2,  1, 11,  5,  1, 10, 10,  1,\n",
       "         1,  1, 10,  9,  1,  1,  1,  1,  2, 11,  1,  1,  1,  1, 11,  6,  1,  6,\n",
       "         1,  1,  1, 11,  1,  9,  1,  1,  1,  1,  1,  8,  1, 10,  7, 10, 15,  1,\n",
       "         2,  5,  9, 15, 14,  1,  3,  1,  1,  1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayo[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APCER: 0.049848526576700636\n",
      "BPCER: 0.010320936243538196\n",
      "ACER: 0.030084731410119414\n"
     ]
    }
   ],
   "source": [
    "from metrics import calculate_metrics\n",
    "\n",
    "# y_attack_types = np.load(r'normal_labels2.npy')\n",
    "# pred = np.load(r'normal_predictions.npy')\n",
    "\n",
    "pred_y = np.where(test_predicted_cat_labels_cpu == 1, 0, 1)\n",
    "# rreal = np.where(test_cat_labels_cpu == 1, 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "apcer, bpcer, acer = calculate_metrics(ayo, pred_y)\n",
    "\n",
    "\n",
    "print('APCER: ' + str(apcer))\n",
    "print('BPCER: ' + str(bpcer))\n",
    "print('ACER: ' + str(acer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    '''\n",
    "    calculates the confusion matrix\n",
    "\n",
    "    parameters:\n",
    "        y_true (list): A list with the true values as in,\n",
    "                                0 - negative\n",
    "                                1 - positive\n",
    "\n",
    "        y_pred (list): A list with the predictions as in,\n",
    "                                0 - negative\n",
    "                                1 - positive\n",
    "    returns:\n",
    "        cm (list): A list with the values for TN, FP, FN, TP (true negatives, false positives, false negatives and false positives)\n",
    "    '''\n",
    "    cm = [0, 0, 0, 0] # tn, fp, fn, tp\n",
    "    for y, y_hat in zip(y_true, y_pred):\n",
    "        if(y == 0): # false\n",
    "            if(y_hat == 0):\n",
    "                cm[0] += 1 # tn\n",
    "            else:\n",
    "                cm[1] += 1 # fp\n",
    "        elif(y == 1): # true\n",
    "            if(y_hat == 0):\n",
    "                cm[2] += 1 # fn\n",
    "            else:\n",
    "                cm[3] += 1 # tp\n",
    "                \n",
    "    return cm\n",
    "\n",
    "\n",
    "def calculate_metrics(y_attack_types, y_pred, threshold=0.5):\n",
    "    '''\n",
    "    calculates the metrics APCER, BPCER and ACER as defined for the OULU dataset.\n",
    "\n",
    "    parameters:\n",
    "        y_attack_types (list): A list with the labels for the samples as in,\n",
    "                                1 - live samples\n",
    "                                2 - print attack 1\n",
    "                                3 - print attack 2\n",
    "                                4 - display attack 1\n",
    "                                5 - display attack 2\n",
    "\n",
    "        y_pred_display (list): A list with the predictions as in,\n",
    "                                0 - attack\n",
    "                                1 - live\n",
    "\n",
    "                                or\n",
    "\n",
    "                                [0-1] float binarized if threshold bellow\n",
    "\n",
    "        pred_threshold (int) [0-1]: used to binarize predictions\n",
    "\n",
    "    returns:\n",
    "        apcer (float) [0-1] attack presentation classification error rate\n",
    "        bpcer (float) [0-1] bona fide presentation classification error rate\n",
    "        acer (float) [0-1] average classification error rate\n",
    "        apcer_mean (float): mean of APCER values across print and display attacks\n",
    "        apcer_variance (float): variance of APCER values across print and display attacks\n",
    "        bpcer_mean (float): mean of BPCER values across print and display attacks\n",
    "        bpcer_variance (float): variance of BPCER values across print and display attacks\n",
    "        acer_mean (float): mean of ACER values across print and display attacks\n",
    "        acer_variance (float): variance of ACER values across print and display attacks\n",
    "    '''\n",
    "\n",
    "    y_pred = [(0 if y >= threshold else 1) for y in y_pred] # binarize y_pred using threshold\n",
    "    y_true = [(0 if y == 1 else 1) for y in y_attack_types] # get y_true from the y_attack_types\n",
    "\n",
    "    # from now on 1=attack and 0=live\n",
    "\n",
    "    print_attack_indices = [index for index, element in enumerate(y_attack_types) if element in [1,2,3]]\n",
    "    display_attack_indices = [index for index, element in enumerate(y_attack_types) if element in [1,4,5]]\n",
    "\n",
    "    y_true_print_attack = [y_true[i] for i in print_attack_indices]\n",
    "    y_pred_print_attack = [y_pred[i] for i in print_attack_indices]\n",
    "    y_true_display_attack = [y_true[i] for i in display_attack_indices]\n",
    "    y_pred_display_attack = [y_pred[i] for i in display_attack_indices]\n",
    "\n",
    "    # tn, fp, fn, tp\n",
    "    cm_print_attack = confusion_matrix(y_true_print_attack, y_pred_print_attack) # confusion matrix for print attack\n",
    "    cm_display_attack = confusion_matrix(y_true_display_attack, y_pred_display_attack) # confusion matrix for display attack\n",
    "\n",
    "    try:\n",
    "        apcer_print = cm_print_attack[2] / (cm_print_attack[3] + cm_print_attack[2]) # fn / (tp + fn)\n",
    "    except:\n",
    "        apcer_print = 0.0\n",
    "\n",
    "    try:\n",
    "        apcer_display = cm_display_attack[2] / (cm_display_attack[3] + cm_display_attack[2]) # fn / (tp + fn)\n",
    "    except:\n",
    "        apcer_display = 0.0\n",
    "\n",
    "    try:\n",
    "        bpcer_print = cm_print_attack[1] / (cm_print_attack[1] + cm_print_attack[0]) # fp/(fp + tn)\n",
    "    except:\n",
    "        bpcer_print = 0.0\n",
    "\n",
    "    try:\n",
    "        bpcer_display = cm_display_attack[1] / (cm_display_attack[1] + cm_display_attack[0]) # fp/(fp + tn)\n",
    "    except:\n",
    "        bpcer_display = 0.0\n",
    "\n",
    "    apcer = max(apcer_print, apcer_display) # max of both apcer (print, display) attack presentation classification error rate\n",
    "    bpcer = max(bpcer_print, bpcer_display) # max of both bpcer (print, display) bona fide presentation classification error rate\n",
    "\n",
    "    acer = (apcer + bpcer) / 2 # average between apcer and bpcer\n",
    "\n",
    "    apcer_values = [apcer_print, apcer_display]\n",
    "    bpcer_values = [bpcer_print, bpcer_display]\n",
    "    acer_values = [(apcer_print + bpcer_print) / 2, (apcer_display + bpcer_display) / 2]\n",
    "\n",
    "    apcer_mean = sum(apcer_values) / len(apcer_values)\n",
    "    apcer_variance = sum((x - apcer_mean) ** 2 for x in apcer_values) / len(apcer_values)\n",
    "\n",
    "    bpcer_mean = sum(bpcer_values) / len(bpcer_values)\n",
    "    bpcer_variance = sum((x - bpcer_mean) ** 2 for x in bpcer_values) / len(bpcer_values)\n",
    "\n",
    "    acer_mean = sum(acer_values) / len(acer_values)\n",
    "    acer_variance = sum((x - acer_mean) ** 2 for x in acer_values) / len(acer_values)\n",
    "\n",
    "    return apcer, bpcer, acer, apcer_mean, apcer_variance, bpcer_mean, bpcer_variance, acer_mean, acer_variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = np.where(test_predicted_cat_labels_cpu == 1, 0, 1)\n",
    "# rreal = np.where(test_cat_labels_cpu == 1, 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "apcer, bpcer, acer, apcer_mean, apcer_variance, bpcer_mean, bpcer_variance, acer_mean, acer_variance = calculate_metrics(ayo, pred_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APCER: 0.049848526576700636\n",
      "APCER mean: 0.04420294403339718\n",
      "APCER variance: 3.187260225325274e-05\n",
      "BPCER: 0.010320936243538196\n",
      "BPCER mean: 0.010320936243538196\n",
      "BPCER variance: 0.0\n",
      "ACER: 0.030084731410119414\n",
      "ACER mean: 0.027261940138467687\n",
      "ACER variance: 7.968150563313174e-06\n"
     ]
    }
   ],
   "source": [
    "print('APCER: ' + str(apcer))\n",
    "print('APCER mean: ' + str(apcer_mean))\n",
    "print('APCER variance: ' + str(apcer_variance))\n",
    "\n",
    "\n",
    "print('BPCER: ' + str(bpcer))\n",
    "print('BPCER mean: ' + str(bpcer_mean))\n",
    "print('BPCER variance: ' + str(bpcer_variance))\n",
    "\n",
    "print('ACER: ' + str(acer))\n",
    "print('ACER mean: ' + str(acer_mean))\n",
    "print('ACER variance: ' + str(acer_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facerec_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
